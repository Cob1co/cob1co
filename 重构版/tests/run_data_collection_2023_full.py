"""è¿è¡Œ Phase 3 DataCollectorï¼ŒåŸºäº 2023 å¹´ 1-12 æœˆæ•°æ®æ”¶é›†è®­ç»ƒæ ·æœ¬ï¼ˆOracle æ–¹æ¡ˆï¼‰ã€‚

è¯´æ˜ï¼š
- å¯¹æ¯ä¸ªæœˆè°ƒç”¨ä¸€æ¬¡ DataCollector.collect_month(year=2023, month=m, save=False)ï¼›
- å°†æ‰€æœ‰æœˆä»½çš„æ ·æœ¬åˆå¹¶ä¸ºä¸€ä¸ªå¤§åˆ—è¡¨ï¼›
- æœ€ç»ˆç»Ÿä¸€ä¿å­˜åˆ° phase3_config.yaml ä¸­ data.transformer_training_data æŒ‡å®šçš„è·¯å¾„ï¼›
- åœ¨ç»ˆç«¯æ‰“å°æ€»æ ·æœ¬æ•°å’Œå…¨å¹´çš„æœ€ä¼˜æƒé‡åˆ†å¸ƒç»Ÿè®¡ã€‚

ä½¿ç”¨æ–¹æ³•ï¼ˆåœ¨é¡¹ç›®æ ¹ç›®å½•ï¼‰ï¼š

    python tests/run_data_collection_2023_full.py

æ³¨æ„ï¼š
- è¯¥è„šæœ¬è¿è¡Œæ—¶é—´è¾ƒé•¿ï¼ˆçº¦ä¸ºå•æœˆ 3 æœˆçš„ 10-12 å€ï¼‰ï¼Œå»ºè®®ç©ºé—²æ—¶è¿è¡Œï¼›
- ä¼šè¦†ç›–åŸæ¥çš„ transformer_training_data.pklï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œè¯·äº‹å…ˆç¡®è®¤ä¸å†éœ€è¦æ—§çš„ 3 æœˆå°æ•°æ®é›†ã€‚
"""

from __future__ import annotations

import sys
from pathlib import Path
from collections import Counter
from typing import Any, Dict, List

import yaml
import numpy as np
import pickle

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT))

from LMPC.training.data_collector import DataCollector  # noqa: E402


def main() -> None:
    print("=" * 70)
    print("ğŸš€ Phase 3 DataCollector - 2023å…¨å¹´ (Oracle)")
    print("=" * 70)

    # åŠ è½½é…ç½®
    config_path = PROJECT_ROOT / "LMPC" / "phase3_config.yaml"
    if not config_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {config_path}")

    with open(config_path, "r", encoding="utf-8") as f:
        config: Dict[str, Any] = yaml.safe_load(f)

    # åˆå§‹åŒ– DataCollector
    collector = DataCollector(config)

    # éœ€è¦æ”¶é›†çš„æœˆä»½ï¼š1-12 æœˆ
    months = list(range(1, 13))

    all_samples: List[Dict[str, Any]] = []
    counter: Counter = Counter()

    for month in months:
        print("\n" + "-" * 70)
        print(f"ğŸ“‹ å¼€å§‹æ”¶é›† 2023-{month:02d} çš„è®­ç»ƒæ•°æ®...")
        dataset = collector.collect_month(year=2023, month=month, save=False)

        num_samples = len(dataset)
        print(f"âœ… 2023-{month:02d} æ”¶é›†å®Œæˆï¼Œæ ·æœ¬æ•°: {num_samples}")

        all_samples.extend(dataset)

        # æ›´æ–°å…¨å¹´æƒé‡ç»Ÿè®¡
        for s in dataset:
            w = tuple(np.round(s["optimal_weights"], 3))
            counter[w] += 1

    total_samples = len(all_samples)
    print("\n" + "=" * 70)
    print(f"âœ… 2023 å…¨å¹´æ”¶é›†å®Œæˆï¼Œæ€»æ ·æœ¬æ•°: {total_samples}")

    if total_samples == 0:
        print("âš ï¸ è­¦å‘Šï¼šå…¨å¹´æœªç”Ÿæˆä»»ä½•æ ·æœ¬ï¼Œè¯·æ£€æŸ¥æ•°æ®å¯¹é½å’Œé…ç½®ã€‚")
        return

    # ä¿å­˜åˆ°é…ç½®ä¸­æŒ‡å®šçš„è·¯å¾„ï¼ˆä¼šè¦†ç›–åŸæ–‡ä»¶ï¼‰
    data_cfg = config.get("data", {})
    rel_path = data_cfg.get("transformer_training_data", "data/transformer_training_data.pkl")
    out_path = PROJECT_ROOT / rel_path
    out_path.parent.mkdir(parents=True, exist_ok=True)

    with open(out_path, "wb") as f:
        pickle.dump(all_samples, f)

    print(f"\nâœ… å…¨å¹´è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {out_path}ï¼Œæ ·æœ¬æ•°: {total_samples}")

    # æ‰“å°å…¨å¹´æœ€ä¼˜æƒé‡åˆ†å¸ƒ
    print("\nğŸ“Š å…¨å¹´æœ€ä¼˜æƒé‡åˆ†å¸ƒ (alpha_soc, alpha_grid, alpha_cost) â†’ è®¡æ•°ï¼š")
    for w, c in counter.most_common():
        print(f"  {w}: {c}")

    print("\nâœ… DataCollector å…¨å¹´è¿è¡Œç»“æŸï¼")


if __name__ == "__main__":
    main()
